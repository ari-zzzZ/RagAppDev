{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "deepseek_api_key=os.environ['DEEPSEEK_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E1979CBBE0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E1989C2110>, root_client=<openai.OpenAI object at 0x000001E194B13FA0>, root_async_client=<openai.AsyncOpenAI object at 0x000001E1979CBC40>, temperature=0.6, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.6)\n",
    "#输出实例llm的内存地址\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'几种常用的超参数设置包括：\\n\\n· model_name：所要使用的模型，默认为 ‘gpt-3.5-turbo’，参数设置与 OpenAI 原生接口参数设置一致。\\n\\n· temperature：温度系数，取值同原生接口。\\n\\n· openai_api_key：OpenAI API key，如果不使用环境变量设置 API Key，也可以在实例化时设置。\\n\\n· openai_proxy：设置代理，如果不使用环境变量设置代理，也可以在实例化时设置。\\n\\n· streaming：是否使用流式传输，即逐字输出模型回答，默认为 False，此处不赘述。\\n\\n· max_tokens：模型输出的最大 token 数，意义及取值同上。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.6, model_name='gpt-3.5-turbo', openai_api_key=openai_api_key)\n",
    "'''几种常用的超参数设置包括：\n",
    "\n",
    "· model_name：所要使用的模型，默认为 ‘gpt-3.5-turbo’，参数设置与 OpenAI 原生接口参数设置一致。\n",
    "\n",
    "· temperature：温度系数，取值同原生接口。\n",
    "\n",
    "· openai_api_key：OpenAI API key，如果不使用环境变量设置 API Key，也可以在实例化时设置。\n",
    "\n",
    "· openai_proxy：设置代理，如果不使用环境变量设置代理，也可以在实例化时设置。\n",
    "\n",
    "· streaming：是否使用流式传输，即逐字输出模型回答，默认为 False，此处不赘述。\n",
    "\n",
    "· max_tokens：模型输出的最大 token 数，意义及取值同上。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='。但是，爱情不应该被距离所限制，如果真心相爱，无论距离有多远，都应该努力在一起。或许可以寻找一种妥协，互相努力，争取在一起的机会。不要因为距离而放弃爱情，或许你们可以找到一种解决办法，让彼此的爱情更加坚固。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 130, 'prompt_tokens': 56, 'total_tokens': 186, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2b75fb2b-e833-497d-8702-16d88aaa7533-0', usage_metadata={'input_tokens': 56, 'output_tokens': 130, 'total_tokens': 186, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"说不爱是假的，可你不会来香港，我也不会去英国，我们就在世界的两级，各自安好，再无牵挂\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个翻译助手，可以帮助我将 中文 翻译成 英文.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='我带着比身体重的行李，游入尼罗河底，经过几道闪电 看到一堆光圈，不确定是不是这里。', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"你是一个翻译助手，可以帮助我将 {input_language} 翻译成 {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "text = \"我带着比身体重的行李，\\\n",
    "游入尼罗河底，\\\n",
    "经过几道闪电 看到一堆光圈，\\\n",
    "不确定是不是这里。\\\n",
    "\"\n",
    "messages  = chat_prompt.format_messages(input_language=\"中文\", output_language=\"英文\", text=text)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I entered the Nile River with luggage heavier than my body, and swam to the bottom. After a few flashes of lightning, I saw a pile of halos, unsure if this was the place.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 95, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e0fe98fa-6a64-4ed5-8957-fcb6b3e681e1-0', usage_metadata={'input_tokens': 95, 'output_tokens': 42, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output  = llm.invoke(messages)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁?\"},\n",
    "    ],\n",
    "    stream=False,\n",
    "    temperature=0.6\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
